\chapter{Эксперименты}
\label{chapter:experiments}
В данной главе представлена экспериментальная часть работы. Сравнение результатов работы алгоритма выявления предпочтений \enquote{при прочих равных} с другими методами обучения предпочтениям является ключевой частью данного исследования.

Глава состоит из четырех разделов. В первом описаны алгоритмы, которые были рассмотрены в данной работе. Во втором разделе представлены наборы данных, на которых сравнивались алгоритмы. В третьем описана методика сравнения алгоритмов и представлены результаты экспериментов. И в последней части кратко описаны инструменты, которые были использованы при проведении экспериментов.

\section{Входные данные}
	В данной работе представлена
	апробация Алгоритма проводилась на двух наборах данных: набор данных о пользовательских предпочтениях в автомобилях и набор данных о предпочтениях в суши. Ниже подробно описан каждый из наборов данных.
	
	%TODO: перенести в секцию с описанием алгоритма
	%\subsection{Искусственный набор данных}
		%Искусственный набор взят из \cite{Obiedkov:2013}. Этот набор данных состоит из семи объектов, пять из которых представлены на рис.~\ref{fig:pcxt}. Еще два объекта: $c_6={minivan, red, bright}$ и $c_7={SUV, red, bright}$. Эти данные не много могут сказать о качестве работы алгоритма, но их можно использовать для базовой проверки его возможностей.
	
	\subsection{Набор данных об автомобильных предпочтениях}
	\label{subsec:cars_description}
		Первый реальный набор данных собран Аббаснеджадом и др. для \cite{dataset:Abbasnejad:2013}. Для сбора пользовательских предпочтений авторы использовали краудсорсинговую платформу Amazon Mechanical Turk\footnote{mturk.com – информация о проекте Amazon Mechanical Turk}. Набор данных состоит из двух экспериментов\footnote{Данные размещены по адресу: http://users.cecs.anu.edu.au/~u4940058/CarPreferences.html}: в первом была собрана информация от 60 пользователей о 10 машинах, во втором – от 60 пользователей о 20 машинах (далее – CD1 и CD2 обозначают первый и второй эксперимент, соответственно). Каждому из респондентов было предложено выбрать более предпочитаемый вариант из каждой пары автомобилей (всего 45 пар). Не все опрашиваемые ответили на полный список вопросов (для некоторых пользователей количество предпочтений менее 45). Причем в CD2 информации о каждой из машин было больше. Далее подробно описана информация, представленная в наборе данных.
		
		\vspace{1em}
		
		\noindent Характеристики пользователей:
		\vspace{-0.7em}
		\begin{itemize}[itemsep=-1.5mm]
			\item ID: уникальный идентификатор пользователя
			\item Образование: отсутствие ответа (0), старшая школа (1), бакалавриат (2), PhD (3)
			\item Возраст: отсутствие ответа (0), меньше 25 (1), от 25 до 30 (2), от 30 до 35 (3), больше 40 (4)
			\item Пол: отсутствие ответа (0), мужской (1), женский (2)
			\item Регион: отсутствие ответа (0), юг (1), запад (2), северо-восток (3), средний запад (4)
			\item Количество правильных ответов на контрольные вопросы: 3, 4 или 5
		\end{itemize}
		Данные собирались среди американской аудитории. Каждому пользователю было задано по пять контрольных вопросов, каждый из которых является одним из пользовательских предпочтений в обратном порядке (например, если пользователь указал, что $o_1 < o_5$, то контрольный вопрос имеет вид $o_5 < o_1?$, где $o_1$ и $o_5$ – какие-то объекты). На основе количества правильных ответов на контрольные вопросы можно судить о согласованности пользовательских предпочтений.
		
		\vspace{1em}
		
		\noindent Признаки машин:
		\vspace{-0.7em}
		\begin{enumerate}[itemsep=-1.5mm]
			\item Тип кузова: седан (1), SUV\footnote{SUV (англ. Sport Utility Vehicle или Suburban Utility Vehicle) – подобие внедорожника} (2), хэтчбек (3)
			\item Коробка передач: ручная (1), автоматическая (2)
			\item Объем двигателя: 2.5L, 3.5L, 4.5L, 5.5L, 6.2L
			\item Тип топлива: гибрид (1), не гибрид (2)
			\item Количество ведущих колес: все колеса ведущие (AWD, 4x4) (1), передние колеса ведущие (FWD) (2)
		\end{enumerate} 
		В первом эксперименте не были представлены хэтчбеки, а так же не использовалась информация о количестве ведущих колес.
	
	\subsection{Набор данных о предпочтениях в суши}
	\label{subsec:sushi_description}
		Набор данных собран Камишимой и Акахо и использован ими в \cite{Kamishima:2003}, \cite{Kamishima:2006} и других работах. Авторы опрашивали 5000 человек об их предпочтениях в суши (всего 100 наименований). При сборе данных авторы просили пользователей заполнить несколько опросников, в результате чего были сформированы 3 набора данных\footnote{Набор данных о предпочтениях суши доступен по адресу: http://www.kamishima.net/sushi/}:
		\begin{enumerate}[itemsep=-1.5mm]
			\item Выбрав 10 наиболее популярных суши, авторы попросили каждого из участников проранжировать их. В результате получен список из 5000 ранжирований. (в дальнейшем этот набор данных обозначается как SDa)
			\item Выбирая 10 случайных суши из 100 (выбор не равновероятностный, он основан на популярности суши), авторы предлагали каждому из пользователей их проранжировать. (в дальнейшем этот набор данных обозначается как SDb)
			\item Используя тот же набор суши (10 из 100), участники опроса должны были поставить каждой из альтернатив оценку от 0 до 4, включительно. В работе эти данные не используются.
		\end{enumerate}
		
		В связи со спецификой японской культуры еды, авторы подробно указывают место жительства каждого из участников, а так же место его жительства до 15 лет. На основе этой информации для выявления предпочтений можно использовать методы коллаборативной фильтрации\cite{Ricci:2011}, одну из вариаций которой авторы используют в \cite{Kamishima:2003}.
		
		\vspace{1em}
		
		\noindent Характеристики пользователей:
		\vspace{-0.7em}
		\begin{enumerate}[itemsep=-1.5mm]
			\item ID: уникальный идентификатор пользователя
			\item Пол: мужской (0), женский (1)
			\item Возраст: от 15 до 19 (0), от 20 до 29 (1), от 30 до 39 (2), от 40 до 49 (3), от 50 до 59 (4), больше 60 (5)
			\item Количество времени (секунд), которое ушло у участника на заполнение анкеты
			\itemrange{6} Признаки, связанные с местом проживания человека
		\end{enumerate}
		
		\noindent Признаки суши:
		\vspace{-0.7em}
		\begin{enumerate}[itemsep=-1.5mm]
			\item ID: уникальный идентификатор суши
			\item Название
			\item Стиль: маки (0), другое (1)
			\item Группа: морская еда (0, соответствует подгруппам 0--8), другое (1)
			\item Подгруппа: синекожая рыба (0), красная рыба (1), \dots, овощи (11) 
			\item Жирность: диапазон [0-4], где 0 -- наибольшая жирность
			\item Частота употребления этого вида суши участниками опроса: диапазон [0-3], где 3 -- наибольшая частота
			\item Цена (нормализованная)
			\item Частота продажи суши: диапазон [0-1], где 1 -- наибольшая частота
		\end{enumerate}
	

\section{Проведение экспериментов}
\label{subsec:experiments_desc}
	При проведении экспериментов использовался метод перекресной проверки ($k$-fold cross-validation)\cite{Hastie:2001}. В одной половине экспериментов исходные данные делились на $n$ частей, где $n$ – количество объектов; в другой половине частей было $\frac{n}{2}$, то есть на каждом шаге тестирующий набор данных состоял из двух элементов. В разделах \ref{subsec:exp_cars} -- \ref{subsec:exp_sushi} подробно описаны проведенные эксперименты, а так же представлены их результаты.
	
	Каждый из экспериментов над объектами $O = \{o_1, o_2, \dots, o_n\}$ включал следующие действия:
	\begin{enumerate}
		\item Обучающая выборка $T = O \setminus \{o_i\}$, где $i$ при каждой итерации увеличивается на 1, проходя от 1 до $n$, включительно;
		\item Для каждого $o_j \in T$ с помощью тестируемого алгоритма проверить $o_j \leq o_i$ и $o_j \geq o_i$:
		\begin{enumerate}
			\item Если алгоритм утверждает $o_j \leq o_i$, хотя на самом деле (опираясь на ответы опрашиваемых пользователей) $o_j \geq o_i$, зачислить 1 балл штрафа. Также штраф начисляется и в обратной ситуации: если алгоритм вывел $o_j \geq o_i$, хотя на самом деле $o_j \leq o_i$;
			\item Если алгоритм с \emph{равной} степенью уверенности утверждает и $o_j \leq o_i$, и $o_j \geq o_i$, и при этом пользователь однозначно склонялся к одному из вариантов, начисляется 0.5 баллов штрафа.
		\end{enumerate} 
		\item Находится среднее из штрафов для каждого $(o_j, o_i) \in (T, o_i)$. Если из единицы вычесть это среднее значение, деленное на $n-1$, то будет получен показатель \emph{``правильности''} для $o_i$\footnote{Как видно из описания эксперимента, максимальный штраф, который может получить каждый $o_j \in T$, равен $n-1$. Это получается, если испытываемый алгоритм на каждый запрос отвечает некорректно. Таким образом, если поделить средний штраф по всем $o_j \in T$ на $n-1$, мы получим долю правильных ответов для текущего $o_i$};
		\item После $n$ итераций получено $n$ показателей штрафов (для каждого из объектов $O$). Далее по этим штрафам строится статистика.
	\end{enumerate}
	Второй блок экспериментов был проведен таким же образом, за исключением того, что обучающая выборка не содержала объект $o_j$, с которым сравнивается $o_i$: $T = O \setminus \{o_i, o_j\}$, где $o_j$ меняется на каждой итерации алгоритма.
		
	При проведении экспериментов (описанным выше методом) над \textbf{алгоритмом выявления предпочтений \enquote{при прочих равных}}, реализованным ``как есть'' (согласно описанию раздела \ref{subsec:cp_description}), точность предсказаний оказывается на низком уровне (см. табл.~\ref{tbl:cars_results}).
	Недостаток данного подхода в том, что при использовании Алгоритма \ref{algo:prediction} с реальными данными, практически для любой пары объектов $(o_1,o_2)$ можно найти и пару объектов $(g_1,h_1)$, которая поддерживает утверждение $o_1 \leq o_2$, и пару $(g_2,h_2)$, которая поддерживает противоположное предпочтение – $o_1 \geq o_2$. В таблицах с результатами экспериментов эта реализация обозначена \emph{CP} (Ceteris Paribus). 
	
	Принимая во внимание сказанное, дополнительно было реализовано 3 модификации Алгоритма \ref{algo:prediction}, которые позволяют предсказывать пользовательские предпочтения с более высокой точностью.
	Первая модификация заключается в подсчете количества различных пар $(g,h)$, которые ``поддерживают'' каждое из предпочтений $o_j \leq o_i$ и $o_j \geq o_i$. Таким образом, Алгоритм~\ref{algo:prediction} был изменен в Алгоритм~\ref{algo:CPe}. Для каждых $(o_j, o_i)$ Алгоритм~\ref{algo:CPe} ищет поддержки для $A:=o_j',\: B:=o_i'$ и для $A:=o_i',\: B:=o_j'$. Если первая больше второй, то вывод $o_j \leq o_i$; если вторая больше первой, то $o_i \leq o_j$; иначе альтернативы равнозначны. В дальнейшем этот алгоритм обозначается \emph{CPs} (Cetris Paribus with Support).
	
	\begin{definition}
		\emph{Поддержка} – для данных $A$ и $B$, количество различных пар $(g, h)$, для которых выполняется $\PP \models \DEF$, где $D := A \cap g'$, $E := B \cap h'$ и $F := (M \setminus (A \vartriangle B)) \cap (M \setminus (g' \vartriangle h'))$\footnote{Согласно опр.~\ref{def:context}, $M$ – множество всех признаков.}.
	\end{definition}
	
	\begin{algorithm}
		\caption{\algname{Вычисление поддержки}$(A, B, \PP)$ (основано на Алг.~\ref{algo:prediction})}
		\label{algo:CPe}
		\begin{algorithmic}[1]
			\REQUIRE Содержания объектов $A, B \subseteq M$ и контекст предпочтений $\PP = (G, M, I, \leq)$.
			\ENSURE поддержка $A, B$
			\item[]
			\STATE $S := \emptyset$
			\FORALL{$g \in G$}
			\STATE $D := A \cap g'$
			\FORALL{$h \in G \setminus \{g\}$ таких, что $g \leq h$}
			\STATE $E := B \cap h'$
			\STATE $F := (M \setminus (A \vartriangle B)) \cap (M \setminus (g' \vartriangle h'))$
			\IF{$\PP \models \DEF$}
			\STATE $S := S \cup \{(g, h)\}$
			\ENDIF
			\ENDFOR
			\ENDFOR
			\RETURN $|S|$
		\end{algorithmic}
	\end{algorithm}
	
	Вторая модификация Алгоритма основана на поиске максимальной поддержки для фиксированных $DFE$. Данная модификация меняет Алгоритмы \ref{algo:prediction} и \ref{algo:check} так, что после нахождения $DFE$ проверяется не просто выполнение  $\DEF$ в $\PP$, но считается количество пар $(g,h)$, которые ``подтверждают'' предпочтение $\DEF$. Алгоритмы \ref{algo:prediction_dfe} и \ref{algo:check_dfe} реализуют описанный подход и являются модификациями Алг. \ref{algo:prediction} и \ref{algo:check}, соответственно.
	
	\begin{algorithm}
		\caption{\algname{Предсказание предпочтения}$(A, B, \PP)$ (основан на Алг.~\ref{algo:prediction})}
		\label{algo:prediction_dfe}
		\begin{algorithmic}[1]
			\REQUIRE Содержания объектов $A, B \subseteq M$ и контекст предпочтений $\PP = (G, M, I, \leq)$.
			\ENSURE $\mathbf{c}$, где $c$ является максимальным возможным количеством пар объектов, которые поддерживают некое $\PP \models \DEF$  $\mathbf{0}$, иначе.
			\item[]
			\STATE $c_{\text{max}} := 0$
			\FORALL{$g \in G$}
			\STATE $D := A \cap g'$
			\FORALL{$h \in G \setminus \{g\}$ таких, что $g \leq h$}
			\STATE $E := B \cap h'$
			\STATE $F := (M \setminus (A \vartriangle B)) \cap (M \setminus (g' \vartriangle h'))$
			\STATE $c := \PP \models \DEF$
			\IF{$c > c_{\text{max}}$}
			\STATE $c_{\text{max}} := c$
			\ENDIF
			\ENDFOR
			\ENDFOR
			\RETURN $c_{\text{max}}$
		\end{algorithmic}
	\end{algorithm}

	\begin{algorithm}
		\caption{\algname{Проверить предпочтение}$(\DEF, \PP)$ (основано на Алг.~\ref{algo:check})}
		\label{algo:check_dfe}
		\begin{algorithmic}[1]
			\REQUIRE Предпочтение $\DEF$ над $M$ и контекст предпочтений $\PP = (G, M, I, \leq)$
			\ENSURE $\mathbf{c}$, где $c$ – количество пар, поддерживающих $\PP \models \DEF$; $\mathbf{0}$, если нашлась пара, опровергающая $\PP \models \DEF$.
			\item[]
			\STATE $c := 0$
			\STATE $X := \bigcap_{m \in D}m'$
			\STATE $Y := \bigcap_{m \in E}m'$
			\FORALL{$g \in X$}
			\FORALL{$h \in Y$}
			\IF {$g' \cap {F} = h' \cap {F}$}
			\IF {$g \not\leq h$}
			\RETURN $\mathbf{0}$
			\ELSE 
			\STATE $c := c + 1$
			\ENDIF
			\ENDIF
			\ENDFOR
			\ENDFOR
			\RETURN $c$
		\end{algorithmic}
	\end{algorithm}
	
	\noindent Пусть $c_{lr}$ – результат выполнения Алг.~\ref{algo:prediction_dfe} для пары объектов $(o_l, o_r)$, и $c_{rl}$ – результат для пары $(o_r, o_l)$.
	Если результат $c_{lr} - c_{rl}$ положителен, значит $o_i \leq o_j$; если отрицателен, то $o_j \leq o_i$; иначе альтернативы равнозначны. Данная модификация алгоритма обозначается \emph{CPfs} (Ceteris Paribus with Fixed Support).
	
	Третья модификация Алгоритма является смешением двух вышеописанных подходов. В случае, если результат \ref{eq:CPo} равен нолю, срабатывает подход, основанный на расчете поддержки (см. Алгоритм~\ref{algo:CPe}). Эта модификация обозначается как \emph{CPm} (Ceteris Paribus Mixed).
	
	Помимо описанных модификаций в эксперименте участвуют модификации Алгоритма, основанные на предикатах (см. раздел~\ref{sec:modification}). В таблицах такие алгоритмы имеют суффикс ``, mod'': \emph{CP, mod}, \emph{CPf, mod} и \emph{CPfs, mod}.
	
	С использованием \textbf{алгоритма C4.5} было проведено 3 типа экспериментов. В первом варианте каждая из строк имеет вид: 
	\begin{equation}
	\label{eq:c4.5_unpaired_row}
	\{att_1^l, att_1^r, att_2^l, att_2^r, \dots, att_n^l, att_n^r, [< | >]\}
	\end{equation}
	где $att_i^l \in \{\text{YES}, \text{NO}\} \quad \forall i = \overline{1..n}$ (аналогично для $att_i^r$); \\
	$att_i^l$ ($att_i^r$) показывает наличие или отсутствие признака $i$ у левого (правого) объекта из пары; \\
	последний элемент строки показывает класс пары: правый объект предпочитается левому (в случае $<$) или левый правому (в случае $>$). \\
	Как видно, в данном случае каждая строка обучающей выборки содержит $2n + 1$ элементов, где $n$ – количество всех признаков. Далее этот алгоритм обозначается как \emph{C4.5 unpaired}.
	
	Во втором варианте экспериментов с алгоритмом C4.5 в каждой строке обучающей выборки признаки сгруппированы по их типу (например, ``тип кузова''). Таким образом, строки имеют вид:
	\begin{equation}
	\label{eq:c4.5_paired_row}
	\{(att_{[1]}^l, att_{[1]}^r), (att_{[2]}^l, att_{[2]}^r), \dots, (att_{[k]}^l, att_{[k]}^r), [< | >]\}
	\end{equation}
	где каждая из пар $(att_{[i]}^l, att_{[i]}^r)$ показывает признаки типа $i$ (например, признаком $i=2$ может быть ``цвет интерьера'') левого и правого объектов пары предпочтения. \\
	Как видно, в данном случае каждая строка обучающей выборки содержит $k + 1$ элементов, где $k$ – количество категорий признаков. \emph{Стоит отметить, что в данном примере накладываются дополнительные ограничения на входные данные. Если первая адаптация алгоритма C4.5 допускала наличие любых признаков у объекта, то эта версия допускает лишь одно значение для каждой из категорий признаков (например, автомобиль может быть или седаном, или хэтчбеком, но не одновременно, что вполне соответствует реальности).} Далее этот вариант использования алгоритма обозначается как \emph{C4.5 paired}.
	
	Наконец, третий вариант использования алгоритма C4.5 основан на его возможности работать с числовыми признаками. В этом случае каждая из строк имеет тот же вид, что и \eqref{eq:c4.5_paired_row}, за исключением числовых категорий (в случае автомобилей это тип двигателя). Для числовых категорий вместо пары указана разность числовых показателей левого и правого объекта пары предпочтения. Например, в случае автомобильных двигателей вместо пары $(2.5L, 4.5L)$ будет указано $-2$. Далее этот вариант использования алгоритма обозначается как \emph{C4.5 paired, numeric}. 
	
	Наивный \textbf{Байесовский классификатор} (далее – \emph{Naive Bayes}), а так же классификатор, основанный на \textbf{Байесовской сети} (далее – \emph{Bayes Net}), используют представление данных \eqref{eq:c4.5_unpaired_row}. 

	Таблица содержит 7 столбцов: в первом указано сокращенное название испытываемого метода; следующие три столбца показывают качество работы алгоритмов в случае, когда из набора данных был удален 1 объекта; соответственно, последний три столбца показывают результаты испытаний в ситуации, когда удалялось 2 объекта (о методе проведения испытаний см. раздел~\ref{subsec:experiments_desc}). Как видно, каждый из алгоритмов характеризует по 3 величины: ``правильность'' (accuracy), точность (precision) и полнота (recall). Правильность рассчитывается методом, показанным в разделе~\ref{subsec:experiments_desc}. Определения \ref{def:precision} и \ref{def:recall} формализуют понятия точности и полноты, соответственно. Каждая из величин, представленных в таблице, является усредненной по всем пользователям. Так же для каждой из них указано стандартное отклонение (standard deviation).
	
	\begin{definition}
		\label{def:precision}
		\emph{Точность} равна отношению истинно-положительных результатов к сумме ложно-положительных и истинно-положительных: $P = \frac{TP}{TP + FP}$, где $TP$ – истинно-положительный результат, а $FP$ – ложно-положительный \cite[с.~155]{Manning:2008}. В контексте выявления предпочтений точность показывает долю корректно выявленных предпочтений относительно всех предпочтений, которые вывел алгоритм.
	\end{definition}
	
	\begin{definition}
		\label{def:recall}
		\emph{Полнота} равна отношению истинно-положительных результатов к сумме ложно-положительных и ложно-отрицательных: $R = \frac{TP}{TP + FN}$, где $TP$ – истинно-положительный результат, а $FN$ – ложно-отрицательный \cite[с.~155]{Manning:2008}. В контексте выявления предпочтений полнота показывает долю корректно выявленных предпочтений относительно всех существующих корректных предпочтений.
	\end{definition}
	
	\subsection{Набор данных об автомобильных предпочтениях}
	\label{subsec:exp_cars}
		Как указано в разделе~\ref{subsec:cars_description}, набор данных с предпочтениями состоит из 10 автомобилей и 60 пользователей. Пользователи, которые не были последовательны в своих ответах, в рассматриваемых экспериментах не участвовали. Таким образом, остался 31 респондент, каждый из которых ответил на 43-45 вопросов. Для пар объектов, про которые респондент не дал ответа, штраф не начисляется при любом выводе алгоритма. Несмотря на то, что Алгоритм~\ref{algo:prediction} оперирует предпорядками, описываемая в работе реализация допускает наличие циклов в графе предпочтений.
	
		Результаты экспериментов, проведенные над набором данных с предпочтениями в автомобилях, представлены в табл.~\ref{tbl:cars_results}. На ее основе можно сделать некоторые выводы о свойствах рассматриваемых алгоритмов. Разные модификации алгоритма выявления предпочтений \enquote{при прочих равных}, который является основным в данной работе, демонстрируют различные характеристики. Так, базовая реализация довольно точно предсказывает предпочтения: 93.48\% и 91.31\% за первый и второй эксперименты, соответственно. Тем не менее, показатель полноты в обоих экспериментах на порядок ниже точности. Эта ситуация возникает из-за того, что при удалении двух элементов в контексте предпочтений остается меньше объектов, и в итоге алгоритм не может принять ``уверенного'' решения. В результате этого часто возникают ложно-негативные срабатывания, из-за которых и падает показатель полноты. Похожий эффект наблюдается у CPfs, где значения правильности и полноты хоть и выше предыдущего варианта, но показатели второго эксперимента ощутимо хуже первого. Эффекта ухудшения статистики при увеличении числа удаляемых элементов практически не наблюдаются для реализации алгоритма CPs. В случае ``автомобильного'' набора данных алгоритм стабильно находит достаточное количество пар $(g,h)$, которые подтверждают то или иное предпочтение. Достаточно стабильно работает и смешанный подход – CPm. Этот подход не дает серьезного прироста качества предсказаний по сравнению с CPfs, и при этом показатели этого алгоритма ниже CPs (несмотря на то, что в ряде случаев CPm сводится к CPs).
		
		При сравнении реализаций Алгоритма с модификациями, основанными на предикатах, нетрудно заметить, что последние всегда показывают более высокие результаты. Это связано с тем, что при наличии числовых признаков предикаты точнее отражают мнение пользователя. Например, выбирая, что объект с двигателем 5.5L лучше объекта с двигателем 3.5L, респондент скорее всего имел в виду, что у первого объекта должен быть двигатель большего объема, в не зависимости от конкретных значений. Этим же можно объяснить факт превосходства \emph{C4.5 paired, num} над алгоритмами, работающими исключительно с категориальными признаками.  
		
		
	\begin{sidewaystable}[ph!]
		\centering
		\tablecaption{Автомобили: результаты экспериментов}
		\begin{tabular}{|l|ccc|ccc|}
			\hline
			\multirow{2}{*}{Метод}   & \multicolumn{3}{c|}{1-out}                             & \multicolumn{3}{c|}{2-out}         \\ \cline{2-7}  
									 & правильность \%  & точность \%      & полнота \%       & правильность \%   & точность \%       & полнота \% \rule{0pt}{2.4ex} \\ \hline
			CP 						 & $59.09 \pm 3.08$ & $93.48 \pm 9.3$  & $19.46 \pm 5.09$ & $52.94 \pm 0.97$  & $97.31 \pm 8.71$  & $6.11 \pm 1.91$ \rule{0pt}{2.4ex} \\ 
			CP, mod					 & $67.29 \pm 3.29$ & $93.86 \pm 8.22$ & $38.09 \pm 4.09$ & $57.89 \pm 2.42$ & $95.91 \pm 10.95$ & $16.76 \pm 3.31$ \\ 
			CPs 					 & $84.52 \pm 8.7$  & $85.3 \pm 8.82$  & $97.38 \pm 1.89$ & $82.97 \pm 10.74$ & $83.98 \pm 10.94$ & $96.24 \pm 3.21$ \\
			CPs, mod				 & $85.93 \pm 7.64$ & $86.47 \pm 7.64$ & $98.18 \pm 1.65$ & $84.77 \pm 10.45$ & $85.83 \pm 10.78$ & $96.54 \pm 2.58$ \\
			CPfs					 & $76.76 \pm 6.62$ & $81.63 \pm 7.89$ & $81.92 \pm 3.79$ & $66.91 \pm 8.26$  & $71.01 \pm 9.99$  & $74.25 \pm 6.64$ \\
			CPfs, mod				 & $84.64 \pm 7.94$ & $86.58 \pm 7.83$ & $93.51 \pm 4.21$ & $79.35 \pm 9.1$  & $83.43 \pm 9.95$  & $85.46 \pm 7.43$ \\ 
			CPm						 & $80.13 \pm 6.7$  & $80.5 \pm 6.76 $ & $98.43 \pm 1.29$ & $78.49 \pm 9.48$  & $79.08 \pm 9.57$  & $97.47 \pm 2.85$ \\ 
			C4.5 unpaired			 & $79.91 \pm 7.29$ & $88.44 \pm 9.42$ & $75.75 \pm 4.26$ & $71.61 \pm 8.97$  & $83.23 \pm 13.35$ & $61.55 \pm 7.29$ \\ 
			C4.5 paired  			 & $83.08 \pm 9.07$ & $90.16 \pm 9.72$ & $79.7 \pm 7.26$  & $77.53 \pm 10.48$ & $87.39 \pm 12.83$ & $69.5 \pm 8.46$ \\ 
			C4.5 paired, num 	     & $86.61 \pm 7.21$ & $90.93 \pm 7.55$ & $88.22 \pm 5.04$ & $84.27 \pm 9.15$  & $88.18 \pm 10.08$ & $88.44 \pm 5.36$ \\
			Naive Bayes  			 & $83.76 \pm 7.2$  & $83.88 \pm 7.09$ & $99.44 \pm 0.9$  & $82.69 \pm 9.68$  & $82.7 \pm 9.66$   & $99.89 \pm 0.6$ \\ 
			Bayes Net  				 & $83.6 \pm 6.98$  & $83.74 \pm 6.86$ & $99.29 \pm 1.08$ & $82.26 \pm 10.31$ & $82.26 \pm 10.29$ & $99.88 \pm 0.67$ \\ 
			\hline
		\end{tabular}
		\label{tbl:cars_results}
		
		\bigskip\bigskip
		
		\tablecaption{Суши: результаты экспериментов}
		\begin{tabular}{|l|ccc|ccc|}
			\hline
			\multirow{2}{*}{Метод}   & \multicolumn{3}{c|}{1-out}                             & \multicolumn{3}{c|}{2-out}         \\ \cline{2-7}  
			& правильность \%  & точность \%      & полнота \%       & правильность \%   & точность \%       & полнота \% \rule{0pt}{2.4ex} \\ \hline
			CP, mod    				 & $63.93 \pm 6.01$ & $77.94 \pm 11.76$  & $43.44 \pm 5.87$ & $55.57 \pm 7.75$  & $66.33 \pm 21.63$  & $26.28 \pm 8.83$ \rule{0pt}{2.4ex} \\ 
			CPs, mod				 & $70.44 \pm 8.97$  & $71.31 \pm 9.06$  & $93.12 \pm 4.49$ & $60.08 \pm 13.6$  & $60.42 \pm 14.23$  & $90.63 \pm 8.02$ \\
			CPfs, mod				 & $69.7 \pm 8.9$ & $70.76 \pm 9.03$ & $91.44 \pm 5.91$  & $59.42 \pm 12.87$   & $59.95 \pm 13.95$  & $85.05 \pm 10.59$ \\
			C4.5 paired, num 	     & $63.95 \pm 12.82$ & $67.25 \pm 16.7$ & $64 \pm 21.74$ & $58.39 \pm 13.43$  & $60.07 \pm 19.2$ & $54.44 \pm 21.87$ \\
			\hline
		\end{tabular}
		\label{tbl:sushi_results}
	\end{sidewaystable}
	Качество работы алгоритмов, основанных на классифицирующем дереве C4.5, повышается с увеличением использования возможностей алгоритма. Так, алгоритм, использующий числовые признаки объектов, справляется с задачей классификации (предсказания предпочтения) ощутимо эффективнее по сравнению с реализациями, которые работают исключительно с номинальными признаками. Попарное ``склеивание'' признаков так же улучшает работу алгоритма. В рассматриваемом наборе данных это позволило выиграть от 2 до 8 процентов каждого из показателей.
	
	Алгоритмы, основанные на вероятностных признаках (Naive Bayes и Bayes Net) показали наиболее стабильные результаты. Более того, показатели полноты Байесовских алгоритмов стремятся к 100 процентам, что оставляет вне конкуренции большинство испытываемых алгоритмов. Высокие показатели полноты связаны с практически полным отсутствием ложно-негативных срабатываний.
	
	Для некоторых задач немаловажным фактором может являться разброс показателей (в данном случае показано стандартное отклонение). Например, несмотря на низкие показатели правильности и полноты, CPfs остается более стабильным для различных пользователей (различных наборов пользовательских предпочтений), чем другие подходы. Напротив, показатели алгоритма CPs (с высокими результатами правильности и точности) имеет больший разброс значений.
	
	В целом, выбор алгоритма для выявления предпочтений зависит от конкретных задач. В некоторых случаях целесообразно использовать ``аккуратные'' алгоритмы, дающие высокие показатели точности и низкие полноты, тогда как в других ситуациях имеет смысл пренебречь точностью ради полноты.  
	
	
	\subsection{Набор данных о предпочтениях в суши} 
	\label{subsec:exp_sushi}
		Эксперименты проводились над 500 случайно выбранными пользователями из 5000 представленных. В исследовании участвовал набор данных SDa (см.~\ref{subsec:sushi_description}), который состоит из линейно упорядоченных предпочтений. Каждый объект (суши и т.п.) рассматриваемого набора данных состоит из 7 признаков (ID и название использовать не имеет смысла), четыре из которых числовые, два – бинарные и один многозначный.
	
		Над набором данных проведено 4 эксперимента, результаты которых представлены в \ref{tbl:sushi_results}. Как видно из таблицы, в исследовании участвуют лишь алгоритмы, совместимые с числовыми и многозначными признаками. Как и в случае набора данных с автомобилями, говоря о модификациях Алгоритма, CP показывает наихудшие результаты, за ним следует CPfs, и наиболее корректно предсказывает предпочтения CPs. Однако, в отличие от автомобилей, на этом наборе данных у алгоритма C4.5 показатели хуже. CP и C4.5 показывают практически одинаковую правильность в среднем, однако у последнего гораздо выше квадратичное отклонение; при этом значения полноты у C4.5 ощутимо выше. При сравнении C4.5 с CPs и CPfs первый проигрывает по всем параметрам – у него ниже не только средние показатели, но и значения отклонения.
		
		В целом более низкие показатели по сравнению с ``автомобильным'' набором данных могут быть объяснены тем фактом, что предпочтения в еде хуже поддаются формализации, нежели предпочтения в средствах передвижения. Сортируя ``съедобные'' объекты, респондент, возможно, руководствуется критериями, выходящими за рамки описанных.

\section{Реализация}
	Написано на Java 8. Используется Weka. Еще используется Apache Commons Math.
	<...>
